{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### XGBoost Tutorial\n",
    "\n",
    "Overview on XGBoost; Gradient Boosting Library\n",
    "\n",
    "Reasons for implementation\n",
    "- Popular across multiple languages\n",
    "- Allows for distrubution with both Apache Spark and Pyspark\n",
    "- Support for model inference across a variety of data types (arrays, dataframes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb\n",
    "import numpy as np"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Structures\n",
    "\n",
    "Two types of  structures for training models: numpy arrays and DMatrices. DMatrices are a data structure unique to XGBoost that optimizes for both memory efficiency and training speed. DMatrices are recommended for use with XGBoost.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.random.rand(100, 10)\n",
    "y_train = np.random.randint(2, size=100)\n",
    "X_test = np.random.rand(100, 10)\n",
    "y_test = np.random.randint(2, size=100)\n",
    "\n",
    "\n",
    "\n",
    "dtrain = xgb.DMatrix(X_train, label=y_train)\n",
    "dtest = xgb.DMatrix(X_test, label=y_test)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specifying Parameters\n",
    "\n",
    "There are 3 styles of parameters that can be used to specify parameters for XGBoost:\n",
    "\n",
    "1. General Parameters: Guide the overall functioning\n",
    "2. Booster Parameters: Guide the individual booster (tree/regression) at each step\n",
    "3. Learning Task Parameters: Guide the optimization performed\n",
    "\n",
    "\n",
    "### General Parameters\n",
    "- booster [default=gbtree]\n",
    "    - Select the type of model to run at each iteration. It has 2 options:\n",
    "        - gbtree: tree-based models\n",
    "        - gblinear: linear models\n",
    "- silent [default=0]:\n",
    "    - Silent mode is activated is set to 1, i.e. no running messages will be printed.\n",
    "    - It’s generally good to keep it 0 as the messages might help in understanding the model.\n",
    "- nthread [default to maximum number of threads available if not set]\n",
    "    - This is used for parallel processing and number of cores in the system should be entered\n",
    "    - If you wish to run on all cores, value should not be entered and algorithm will detect automatically\n",
    "- num_pbuffer [set automatically by XGBoost, no need to be set by user]\n",
    "    - This is a parameter that is set automatically by XGBoost to be equal to number of rows in training data. This is used for parallel processing and hence, this parameter should not be set by the user.\n",
    "- num_feature [set automatically by XGBoost, no need to be set by user]\n",
    "    - This is also set automatically by XGBoost and is equal to maximum number of features to be used. If not set by user, XGBoost will automatically select the maximum number of features present in the data.\n",
    "- num_class [set automatically by XGBoost, no need to be set by user]\n",
    "    - This is set automatically by XGBoost and is equal to number of unique classes in the data. It is used for multiclass classification problems. If not set, XGBoost will automatically set to 1 for regression problems and number of classes for classification problems.\n",
    "- eval_metric [ default according to objective parameter ]\n",
    "    - Evaluation metrics for validation data, a default metric will be assigned according to objective (rmse for regression, and error for classification, mean average precision for ranking )\n",
    "    - User can add multiple evaluation metrics separated by ‘,’\n",
    "- seed [default=0]\n",
    "    - The random number seed.\n",
    "    - Can be used for generating reproducible results and also for parameter tuning.\n",
    "\n",
    "### Booster Parameters (Linear Booster)\n",
    "\n",
    "- lambda [default=0, alias: reg_lambda]\n",
    "    - L2 regularization term on weights, increase this value will make model more conservative.\n",
    "- alpha [default=0, alias: reg_alpha]\n",
    "    - L1 regularization term on weights, increase this value will make model more conservative.\n",
    "- lambda_bias [default=0, alias: reg_lambda_bias]\n",
    "    - L2 regularization term on bias, increase this value will make model more conservative.\n",
    "- updater [default=shotgun]\n",
    "    - Algorithm for Inference\n",
    "\n",
    "\n",
    "### Learning Task Parameters\n",
    "\n",
    "- objective [ default=reg:linear ]\n",
    "    - This defines the loss function to be minimized. Mostly used values are:\n",
    "        - binary:logistic –logistic regression for binary classification, returns predicted probability (not class)\n",
    "        - multi:softmax –multiclass classification using the softmax objective, returns predicted class (not probabilities)\n",
    "            - you also need to set an additional num_class (number of classes) parameter defining the number of unique classes\n",
    "        - multi:softprob –same as softmax, but returns predicted probability of each data point belonging to each class.\n",
    "\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Component-Wise Linear Model Gradient Boosting Setup\n",
    "\n",
    "Here we set the objective as squared error by specifying the reg:linear objective. We also set the eval_metric to rmse, which is root mean squared error. Under the assumption of a standard linear model; additional regularization is not specified, (lambda = 0, alpha = 0). The number of rounds is set to 100, which means that 100 linear models will be selected\n",
    "\n",
    "Importantly; each linear model is trained on the feature with the largest gradient magnitude. This is a greedy approach to feature selection, and is a key component of the XGBoost algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "param = {'objective':'reg:squarederror', 'booster':'gblinear',\n",
    "         'updater':'coord_descent','alpha': 0, 'lambda': 0,\n",
    "         'feature_selector': 'greedy','top_k':1,'eta':0.001}\n",
    "\n",
    "param['eval_metric']='rmse'\n",
    "watchlist = [(dtest, 'eval'), (dtrain, 'train')]\n",
    "num_round = 1000"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compatability with Scikit-Learn\n",
    "\n",
    "XGBoost can be wrapped as a scikit-learn estimator. This allows for the use of the scikit-learn API for training and inference. This is useful for cross-validation and grid-searching."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-5 {color: black;background-color: white;}#sk-container-id-5 pre{padding: 0;}#sk-container-id-5 div.sk-toggleable {background-color: white;}#sk-container-id-5 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-5 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-5 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-5 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-5 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-5 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-5 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-5 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-5 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-5 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-5 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-5 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-5 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-5 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-5 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-5 div.sk-item {position: relative;z-index: 1;}#sk-container-id-5 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-5 div.sk-item::before, #sk-container-id-5 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-5 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-5 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-5 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-5 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-5 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-5 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-5 div.sk-label-container {text-align: center;}#sk-container-id-5 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-5 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-5\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBRegressor(alpha=0, base_score=None, booster=&#x27;gblinear&#x27;, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eta=0.001, eval_metric=&#x27;rmse&#x27;,\n",
       "             feature_selector=&#x27;greedy&#x27;, feature_types=None, gamma=None,\n",
       "             gpu_id=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, lambda=0, learning_rate=None,\n",
       "             max_bin=None, max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "             n_estimators=100, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" checked><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBRegressor</label><div class=\"sk-toggleable__content\"><pre>XGBRegressor(alpha=0, base_score=None, booster=&#x27;gblinear&#x27;, callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eta=0.001, eval_metric=&#x27;rmse&#x27;,\n",
       "             feature_selector=&#x27;greedy&#x27;, feature_types=None, gamma=None,\n",
       "             gpu_id=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, lambda=0, learning_rate=None,\n",
       "             max_bin=None, max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "             n_estimators=100, ...)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "XGBRegressor(alpha=0, base_score=None, booster='gblinear', callbacks=None,\n",
       "             colsample_bylevel=None, colsample_bynode=None,\n",
       "             colsample_bytree=None, early_stopping_rounds=None,\n",
       "             enable_categorical=False, eta=0.001, eval_metric='rmse',\n",
       "             feature_selector='greedy', feature_types=None, gamma=None,\n",
       "             gpu_id=None, grow_policy=None, importance_type=None,\n",
       "             interaction_constraints=None, lambda=0, learning_rate=None,\n",
       "             max_bin=None, max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "             max_delta_step=None, max_depth=None, max_leaves=None,\n",
       "             min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "             n_estimators=100, ...)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boosted_regresion = xgb.XGBRegressor(**param)\n",
    "boosted_regresion.fit(X_train, y_train, verbose=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.5092283 , 0.5098041 , 0.5098117 , 0.50728726, 0.5045136 ,\n",
       "       0.5113001 , 0.5044889 , 0.51273537, 0.51384264, 0.50841755,\n",
       "       0.511699  , 0.51606023, 0.50493   , 0.50798434, 0.5067369 ,\n",
       "       0.50631016, 0.5106881 , 0.5100418 , 0.5128517 , 0.51386493,\n",
       "       0.5082587 , 0.50911283, 0.50645244, 0.5053252 , 0.5068168 ,\n",
       "       0.5086351 , 0.51529956, 0.5109724 , 0.5108534 , 0.51142025,\n",
       "       0.51053756, 0.50996286, 0.51328623, 0.5076377 , 0.5063854 ,\n",
       "       0.5105663 , 0.50518596, 0.5093748 , 0.5080307 , 0.51511973,\n",
       "       0.51483965, 0.5069136 , 0.5159051 , 0.5113169 , 0.515719  ,\n",
       "       0.5131129 , 0.50840616, 0.50934434, 0.50524217, 0.51557666,\n",
       "       0.5100183 , 0.51206183, 0.5111399 , 0.51266617, 0.50658846,\n",
       "       0.5139409 , 0.5090528 , 0.5126986 , 0.51089936, 0.5100083 ,\n",
       "       0.5104867 , 0.5093832 , 0.51042724, 0.50744903, 0.5117112 ,\n",
       "       0.5065937 , 0.5158394 , 0.515577  , 0.50447214, 0.5095995 ,\n",
       "       0.5148381 , 0.515874  , 0.5121128 , 0.5110455 , 0.5049269 ,\n",
       "       0.5126828 , 0.5048525 , 0.51284593, 0.5085381 , 0.50903267,\n",
       "       0.5088169 , 0.50641495, 0.5120624 , 0.5075466 , 0.51521933,\n",
       "       0.5135516 , 0.5080436 , 0.5076401 , 0.5109535 , 0.51045173,\n",
       "       0.51601017, 0.51144725, 0.5133103 , 0.50986236, 0.505292  ,\n",
       "       0.51071274, 0.5090937 , 0.51553696, 0.51153404, 0.5125384 ],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boosted_regresion.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.004055962991140083"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boosted_regresion.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'objective': 'reg:squarederror',\n",
       " 'base_score': None,\n",
       " 'booster': 'gblinear',\n",
       " 'callbacks': None,\n",
       " 'colsample_bylevel': None,\n",
       " 'colsample_bynode': None,\n",
       " 'colsample_bytree': None,\n",
       " 'early_stopping_rounds': None,\n",
       " 'enable_categorical': False,\n",
       " 'eval_metric': 'rmse',\n",
       " 'feature_types': None,\n",
       " 'gamma': None,\n",
       " 'gpu_id': None,\n",
       " 'grow_policy': None,\n",
       " 'importance_type': None,\n",
       " 'interaction_constraints': None,\n",
       " 'learning_rate': None,\n",
       " 'max_bin': None,\n",
       " 'max_cat_threshold': None,\n",
       " 'max_cat_to_onehot': None,\n",
       " 'max_delta_step': None,\n",
       " 'max_depth': None,\n",
       " 'max_leaves': None,\n",
       " 'min_child_weight': None,\n",
       " 'missing': nan,\n",
       " 'monotone_constraints': None,\n",
       " 'n_estimators': 100,\n",
       " 'n_jobs': None,\n",
       " 'num_parallel_tree': None,\n",
       " 'predictor': None,\n",
       " 'random_state': None,\n",
       " 'reg_alpha': None,\n",
       " 'reg_lambda': None,\n",
       " 'sampling_method': None,\n",
       " 'scale_pos_weight': None,\n",
       " 'subsample': None,\n",
       " 'tree_method': None,\n",
       " 'validate_parameters': None,\n",
       " 'verbosity': None,\n",
       " 'updater': 'coord_descent',\n",
       " 'alpha': 0,\n",
       " 'lambda': 0,\n",
       " 'feature_selector': 'greedy',\n",
       " 'top_k': 1,\n",
       " 'eta': 0.001}"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boosted_regresion.get_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.00445262])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boosted_regresion.intercept_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.       , 0.       , 0.       , 0.       , 0.       , 0.       ,\n",
       "       0.0121198, 0.       , 0.       , 0.       ])"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boosted_regresion.coef_"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seems to result in sparse solutions but need to confirm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ase",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
