{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learning Hyperparameters Online\n",
    "\n",
    "In the L-1 penalized regression notebook, there is a hyperparameter $\\lambda$ that controls the amount of regularization.  In this notebook, we will see how to outline an algorithm for updating this parameter adaptively online"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assume given our observations we wish to determine a sparse model of the form\n",
    "\n",
    "$$y = X \\beta + \\epsilon$$\n",
    "\n",
    "where $X$ is a $n \\times p$ matrix of observations, $y$ is a $n$-vector of responses, and $\\beta$ is a $p$-vector of coefficients.  We will assume that the observations are independent and identically distributed (i.i.d.) with mean zero and variance $\\sigma^2$. \n",
    "\n",
    "Under the assumptions of a sparse model we can construct the objective as \n",
    "$$ \\min_{\\beta} \\frac{1}{2} \\sum_{i=1}^n (y_i - \\beta^T x_i)^2 + \\lambda \\sum_{j=1}^p |\\beta_j| $$\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ref:  Adaptive regularization for Lasso models in the context of non-stationary data streams  https://arxiv.org/abs/1610.09127"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Update Rule\n",
    "\n",
    "Defining $C(X_{t+1})$ as the cost function for the next observations $X_{t+1}$, we can update the regularization parameter as\n",
    "\n",
    "$$ \\lambda_{t+1} = \\lambda_t + \\epsilon \\ \\frac{\\partial{C (X_{t+1})}}{\\partial{\\hat{\\beta_t}}}\\frac{\\partial{\\hat{\\beta_t}}}{\\partial{\\lambda_t}} $$\n",
    "\n",
    "where $\\alpha$ is a learning rate"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Utilizing the piecweise linear solutions for the Lasso, we can expand the second partial as\n",
    "\n",
    "$$ \\frac{\\partial{\\hat{\\beta_t}}}{\\partial{\\lambda_t}} = -(S_t)^{-1} sign(\\hat{\\beta_t}) $$\n",
    "\n",
    "where $S_t$ is the covariance matrix of the observations $X_t$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_lambda(X,y,beta,lambda_t,epsilon=0.1):\n",
    "    \"\"\"\n",
    "    Update the regularization parameter for the Lasso via a gradient descent algorithm\n",
    "    \"\"\"\n",
    "    \n",
    "\n",
    "    # if active set is empty take a epsilon-size step in the direction of the most correlated predictor (LARS)\n",
    "    if max(abs(beta))==0:\n",
    "        j=np.argmax(np.abs(np.dot(X.T,y)))\n",
    "        beta[j]=1\n",
    "        return lambda_t + epsilon* beta\n",
    "    \n",
    "    # else compute gradient of the parameter estimate to the data\n",
    "    dc_dbt=-2*np.dot(X.T,y) + 2*np.dot(np.dot(X.T,X),beta)\n",
    "    \n",
    "    # compute sample covariance matrix\n",
    "    S=np.cov(X.T)\n",
    "\n",
    "    # inverse of sample covariance matrix\n",
    "    S_inv=np.linalg.inv(S)\n",
    "\n",
    "    # compute gradient of the parameter estimate to the regularization parameter\n",
    "    dbt_dlambda_t= -np.dot(S_inv,np.sign(beta))\n",
    "\n",
    "    lambda_t_1=lambda_t + epsilon*dc_dbt*dbt_dlambda_t\n",
    "\n",
    "    return lambda_t_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ase",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
